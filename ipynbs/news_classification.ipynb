{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/sanika/miniconda3/envs/smai/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fe2c45356b0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "import csv\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from torchtext.vocab import build_vocab_from_iterator, Vocab\n",
    "import re\n",
    "import pickle\n",
    "from typing import List, Tuple, Optional\n",
    "from torch import swapaxes\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "torch.manual_seed(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    data = []\n",
    "    labels = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        for row in reader:\n",
    "            data.append(row[1])\n",
    "            labels.append(row[0])\n",
    "    # delete the first element of the list (header)\n",
    "    del data[0]\n",
    "    del labels[0]\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data (the csv)\n",
    "train_data, train_labels = load_data('./ANLP-2/train.csv')\n",
    "test_data, test_labels = load_data('./ANLP-2/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_data(data):\n",
    "    tokenized_data = []\n",
    "    for text in data:\n",
    "        text = re.sub(r'\\\\', ' ', text)\n",
    "        text = re.sub(r'\\\"', ' ', text)\n",
    "        text = re.sub(r'\\d+', '<NUMBER>', text)\n",
    "        text = text.lower()\n",
    "        text = re.sub(r'[!\"#$%&\\'()*+,-./:;<=>?@^_`{|}~]', ' ', text)\n",
    "        tokenized_data.append(word_tokenize(text))\n",
    "    return tokenized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = tokenize_data(train_data)\n",
    "test_data = tokenize_data(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load vocabulary\n",
    "# load from pt file\n",
    "vocab = torch.load('skip-gram-vocab.pt')\n",
    "\n",
    "word_vectors = torch.load('skip-gram-word-vectors.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print a histogram of the lengths of the sentences\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "sentence_lengths = [len(sentence) for sentence in train_data]\n",
    "plt.hist(sentence_lengths, bins=50)\n",
    "plt.xlabel('Sentence length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of sentence lengths')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_OF_VOCAB = '<OOV>'\n",
    "PAD_TAG = '<PAD>'\n",
    "START_TAG = '<BOS>'\n",
    "END_TAG = '<EOS>'\n",
    "\n",
    "class POSDataset(Dataset):\n",
    "    def __init__(self, sentences, labels, vocabulary: Optional[Vocab] = None):\n",
    "        self.sentences = sentences\n",
    "        self.labels = labels\n",
    "        if vocabulary is None:\n",
    "            self.vocab = build_vocab_from_iterator(self.sentences, specials=[OUT_OF_VOCAB, PAD_TAG])\n",
    "            self.vocab.set_default_index(self.vocab[OUT_OF_VOCAB])\n",
    "        else:\n",
    "            self.vocab = vocabulary\n",
    "\n",
    "        # set default index\n",
    "        self.vocab.set_default_index(self.vocab[OUT_OF_VOCAB])\n",
    "\n",
    "        # Extract unique labels\n",
    "        self.labels_vocab = list(set(self.labels))\n",
    "        # sort\n",
    "        self.labels_vocab.sort()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.vocab.lookup_indices(self.sentences[idx])), torch.tensor(self.labels_vocab.index(self.labels[idx]))\n",
    "\n",
    "    def format(self, batch, encodings) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        # add <BOS> and <EOS> to the sentences\n",
    "        sentences, labels = zip(*batch)\n",
    "        sentences = list(sentences)\n",
    "        # add <BOS> and <EOS> to the sentences\n",
    "        sentences = [torch.tensor([self.vocab[START_TAG]] + list(s) + [self.vocab[END_TAG]]) for s in sentences]\n",
    "\n",
    "        sentences = pad_sequence(sentences, padding_value=self.vocab[PAD_TAG])\n",
    "        sentences = swapaxes(sentences, 0, 1)\n",
    "\n",
    "        # cut sentences off at length 50\n",
    "        sentences = sentences[:, :40]\n",
    "\n",
    "        # one hot encode the labels\n",
    "        labels = [torch.nn.functional.one_hot(torch.tensor(l), num_classes=len(self.labels_vocab)) for l in labels]\n",
    "\n",
    "        # encodings is a dictionary with each index corresponding to a word encoding. Map those to the sentences\n",
    "        # convert sentences to a list of list of tensors\n",
    "        sentences = [[encodings[int(i)] for i in s] for s in sentences]\n",
    "\n",
    "        # zip and return\n",
    "        return list(zip(sentences, labels))\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = POSDataset(train_data, train_labels, vocab)\n",
    "test_dataset = POSDataset(test_data, test_labels, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/sanika/miniconda3/envs/smai/lib/python3.7/site-packages/ipykernel_launcher.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    }
   ],
   "source": [
    "train = train_dataset.format(train_dataset, word_vectors)\n",
    "test = test_dataset.format(test_dataset, word_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train into train and validation\n",
    "train_size = int(0.8 * len(train))\n",
    "val_size = len(train) - train_size\n",
    "train, val = torch.utils.data.random_split(train, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders = {\n",
    "    'train': DataLoader(train, batch_size=128, shuffle=True),\n",
    "    'test': DataLoader(test, batch_size=128, shuffle=False),\n",
    "    'val': DataLoader(val, batch_size=128, shuffle=False)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN_News_Classification(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, num_layers=n_layers, bidirectional=True, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim*2, output_dim)\n",
    "\n",
    "    def forward(self, text):\n",
    "        output, (hidden, cell) = self.rnn(text)\n",
    "        final_output = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1)\n",
    "        output = self.fc(final_output)\n",
    "        return output\n",
    "\n",
    "    def fit(self, loaders, optimizer, criterion, n_epochs, device):\n",
    "        self.to(device)\n",
    "        self.train()\n",
    "        for epoch in range(n_epochs):\n",
    "            self.train()\n",
    "            total_loss = 0  \n",
    "            for i, (sentences, labels) in enumerate(loaders['train']):\n",
    "                # convert sentences to tensors\n",
    "                # sentences = sentences.to(device)\n",
    "                sentences = torch.stack(sentences).to(device)\n",
    "                sentences = sentences.permute(1, 0, 2)\n",
    "                labels = labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                output = self(sentences)\n",
    "                labels = labels.float()\n",
    "                loss = criterion(output, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                total_loss += loss.item()\n",
    "            print(f'Epoch {epoch+1}') \n",
    "            print(f'Loss: {total_loss/len(loaders[\"train\"])}')\n",
    "            \n",
    "            # evaluate\n",
    "            self.eval()\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            total_loss = 0\n",
    "            with torch.no_grad():\n",
    "                for i, (sentences, labels) in enumerate(loaders['val']):\n",
    "                    # convert to tensors\n",
    "                    # sentences = sentences.to(device)\n",
    "                    sentences = torch.stack(sentences).to(device)\n",
    "                    sentences = sentences.permute(1, 0, 2)\n",
    "                    labels = labels.to(device)\n",
    "                    output = self(sentences)\n",
    "                    predicted = torch.argmax(output, dim=1)\n",
    "                    total += labels.size(0)\n",
    "                    original = torch.argmax(labels, dim=1)\n",
    "                    correct += (predicted == original).sum().item()\n",
    "                    labels = labels.float()\n",
    "                    loss = criterion(output, labels)\n",
    "                    total_loss += loss.item()\n",
    "            print(f'Validation Loss: {total_loss/len(loaders[\"val\"])}')\n",
    "            print(f'Validation Accuracy: {correct/total}')\n",
    "\n",
    "            \n",
    "    def evaluate(self, loaders, device):\n",
    "        self.to(device)\n",
    "        self.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for i, (sentences, labels) in enumerate(loaders['test']):\n",
    "                # convert to tensors\n",
    "                sentences = torch.stack(sentences).to(device)\n",
    "                sentences = sentences.permute(1, 0, 2)\n",
    "                labels = labels.to(device)\n",
    "                output = self(sentences)\n",
    "                predicted = torch.argmax(output, dim=1)\n",
    "                labels = torch.argmax(labels, dim=1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        print(f'Test Accuracy: {correct/total}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Loss: 0.5329164936542511\n",
      "Validation Loss: 0.3455353028913762\n",
      "Validation Accuracy: 0.8785833333333334\n",
      "Epoch 2\n",
      "Loss: 0.2902852557897568\n",
      "Validation Loss: 0.30731491950598167\n",
      "Validation Accuracy: 0.8917083333333333\n",
      "Epoch 3\n",
      "Loss: 0.2283319307466348\n",
      "Validation Loss: 0.31260934654385486\n",
      "Validation Accuracy: 0.8920416666666666\n",
      "Epoch 4\n",
      "Loss: 0.18545235445102057\n",
      "Validation Loss: 0.3097534636233715\n",
      "Validation Accuracy: 0.895375\n",
      "Epoch 5\n",
      "Loss: 0.15315355384349824\n",
      "Validation Loss: 0.3212684965989691\n",
      "Validation Accuracy: 0.8969166666666667\n",
      "Epoch 6\n",
      "Loss: 0.1210163178667426\n",
      "Validation Loss: 0.3560660979215135\n",
      "Validation Accuracy: 0.8942083333333334\n",
      "Epoch 7\n",
      "Loss: 0.09911053586006165\n",
      "Validation Loss: 0.3729638399437387\n",
      "Validation Accuracy: 0.895375\n",
      "Epoch 8\n",
      "Loss: 0.08080336098869642\n",
      "Validation Loss: 0.4146778533591869\n",
      "Validation Accuracy: 0.891125\n",
      "Epoch 9\n",
      "Loss: 0.06580434441069762\n",
      "Validation Loss: 0.44249027206542646\n",
      "Validation Accuracy: 0.8879166666666667\n",
      "Epoch 10\n",
      "Loss: 0.05802420016067723\n",
      "Validation Loss: 0.4598477893370263\n",
      "Validation Accuracy: 0.8899583333333333\n"
     ]
    }
   ],
   "source": [
    "model = RNN_News_Classification(len(vocab), 300, 128, len(train_dataset.labels_vocab), 2)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model.fit(loaders, optimizer, criterion, 10, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-86642b9e852c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.evaluate(loaders, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
